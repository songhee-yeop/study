# 카프카 프로듀서: 카프카에 메시지 쓰기
- 카프카 프로듀서 사용법 배움
- 프로듀서 디자인, 주요 요소의 전체적 모습, 객체 생성 등

## 3.1 프로듀서 개요
- 카프카에 메시지를 써야 하는상황 
  - 감사 혹은 분석목적으로 한 사용자 행동 기록
  - 메트릭 기록
  - 로그 메시지 저장
- 사례도 다양
  - 메시지 유실 용납 여부
  - 중복 허용여부
  - 지연 처리율 있는지?
- 카프카에 메시지를 쓰는 작업은 ProducerRecord 객체를 생성함으로써 시작
- 토픽 밸류지정은 필수, 키와 파티션 지정은 선택
- ProducerRecord를 전송하는 API 호출 시 프로듀서는 키와 값 객체가 네트워크 상에서 전송될 수 있도록 직렬화해서 바이트 배열로 변환
- 파티션을 명시적으로 지정하지 않았따면 해당 데이터를 파티셔너에게 보냄
## 3.2 카프카 프로듀서 생성하기
- 메시지를 쓰려면 객체를 생성해야 하는데 카프카 프로듀서는 3개의 필수 속성값 가짐
- bootstrap.servers
  - 프로듀서가 사용할 브로커의 host:port목록
  - 최소 2개 이상 권장
- key.serializer
  - 프로튜서 인터페이스는 임의의 자바 객체를 키 혹은 밸류로 전송할 수 있도록 매개변수화된 타입을 사용할수 있게 한다.
  - 키 직렬화
- value.serializer
  - 밸류 직렬화
~~~java
Properties kafkaProps = new Properties();
kafkaProps.put("bootstrap.servers", "broker1:9092, broker2:9092");
kafkaProps.put("key.sserializer", "org.apache.kafka.common.serialization.StringSerializer");
kafkaProps.put("value.serializer", "org.apache.kafka.common.serialization.StringSerializer");

kafkaProducer<String, String> producer. = new KafkaProducer<String, String>(kafkaProps);
~~~
- 메시지 전송 방법
  - 파이어 앤 포겟
    - 전송만 하고 성공여부 신경 안씀
  - 동기적 전송
    - 성공여부 확인
  - 비동기적 전송
    - send()호출하면 카프카 브로커로부터 응답을 받는 시점으로 콜백함수 호출

## 3.3 카프카로 메시지 전달
~~~java
ProducerRecord<String, String> record = new ProducerRecord<>("CustomerCountry", "Precision Products", "France");
try {
    producer.send();
} catch( Exception e) {
  e.printStackTrace();
}
~~~

### 3.3.1 동기적으로 메시지 전송하기
- 주요 균형점은 성능
- 성능이 낮으므로 실제로 잘 사용되지 않음
~~~java
ProducerRecord<String, String> record = new ProducerRecord<>("CustomerCountry", "Precision Products", "France");
try {
    producer.send().get(); //Future.get 메소드 사용
} catch( Exception e) {
  e.printStackTrace();
}
~~~

### 3.3.2 비동기적으로 메시지 전송
- 메시지를 비동기적으로 전송하고도 에러 처리 위해 프로듀서는 레고드를 전송할 때 콜백 지정 가능
~~~java
private class DemoProducerCallback implements Callback {
    @Override
    public void onCompletion(RecordMetadata recordMetadata, Exception e) {
        if(e != null) {
            e.printStackTrace();
        }
    }
}

ProducerRecord<String, String> record = new ProducerRecord<>("CustomerCountry", "Precision Products", "France");
producer.send(record, new DemoProducerCallback());
~~~

### 3.4 프로듀서 설정하기

### 3.4.1 client.id
- 논리적 식별자

### 3.4.2 acks
- 프로듀서가 임의의 쓰기 작업이 성공했다고 판별하기 위해 얼마나 많은 파티션 레플리카가 해당 레코드를 받아야 하는지 결정
- 기본값은 리더가 해당 레코드를 받은 뒤 쓰기 작업이 성공했다고 응답
- acks=0일때
  - 성공 간주 브로커의 응답 기자리지 않음
  - 매우 높은 처리량이 필요할 때 사용
- acks=1
  - 프로듀서는 리더 레플리카가 메시지를 받는 순간 브로커로부터 성공했다는 응답 받음
  - 리더에 크래시가 난 상태면 메시지 유실 가능
- acks=all
  - 모든 인 싱크 레플리카에 전달된 뒤에야 성공 응답 받음 
  - 가장 안전
  - 지연이 길다.

### 3.4.3 메시지 전달 시간
- 카프카 2.1부터 시간을 두 구간으로 분리
  - send()에 대한 비동기 호출 시작 시작부터 리턴 시간
  - send()에 대한 비동기 호출이 성공적 리턴 시각부터 콜백이 호출될 떄 걸리는 시간
1. max.block.ms
   - 프로듀서가 얼마나 오랫동안 블록되는지 결정
2. delivery.timeout.ms
    - 레코드 전송 준비가 완로된 시점에서부터 브로커의 응답을 받거나 아니면 전송을 포기하게 되는 시점까지의 제한시간을 결정한다.
    - 이 값은 linger.ms와 request.timeout.ms보다 커야 한다.
    - 보통 이것보다 메시지는 빨리 전송
3. request.timeout.ms
    - 프로듀서가 데이터를 전송할 때 서버로부터 응답 받기 위해 얼마나 기다릴것인지 결정
    - 이 값은 각각의 쓰기 요청 후 전송을 포기하기까지의 대기 시간임
4. retries, retry.backoff.ms
    - retries 매개변수는 프로듀서가 메시지 전송을 포기하고 에러를 발생시킬 때까지 메시지를 재전송하는 횟수 결정
    - retry.backoff.ms 매개변수를 통해 간격 조정 가능  그러나 조정을 권장하지 안ㅎ음
    - 크래시 난 브로커가 정상으로 되돌아오기까지의 시간을 테스트한 뒤 delivery.timeout.ms 매개변수를 잡아주는 것을 권장

### 3.4.4 linger.ms
- 현재 배치를 전송하기 전까지 대기하는 시간을 결정
- 배치가 가득 차거나 linger.ms에 설정된 제한 시간이 되었을대 메시지 배치를 전송

### 3.4.5 buffer.memory
- 버퍼 크기결정
- 추가로 호출되는 send()는 max.block.ms동안 블록되어 버퍼 메모리에 공간이 생기기를 기다리게 되는데, 대기하고도 공간확보 안되면 예외 발생

### 3.4.6 compression.type
- snappy, gzip, lz4, zstd중 하나로 설정하면 메시지 압축한 뒤 브로커로 전송
- 보통 Snappy 압축이 좋음.
- gzip은 압축율이 더 좋으나 CPU시간 많이 잡아먹으므로 제한적으로 사용

### 3.4.7 batch.size
- 각각의 배치에 사용될 메모리의 양 결정(byte단위)

### 3.4.8 max.in.flight.requests.per.connection
- 프로듀서가 서버로부터 응답받지 못한 상태에서 전송할 수 있는 최대 메시지의 수
- 2일때 처리량이 최대이지만 기본값인 5도 비슷한 성능 보여줌

### 3.4.9 max.request.size
- 프로듀서가 전송하는 쓰기 요청의 크기 결정

### 3.4.10 recieve.buffer.size, send.buffer.bytes
- 데이터를 읽거나 쓸 때 소케시 사용하는 TCP 송수신 버퍼의 크기 결정
- -1일경우 운영체제의 기본값
- 올려잡는게 좋음

### 3.4.11 enable.idempotence
- 0.11부터 카프카는 '정확히 한 번' 의미구조를 지원
- acks=all, 실패시 재시도 충분히 하도록 delivery.timeout.ms는 큰값 => 메시지는 반드시 최소 한번 카프카에 쓰여짐
  - 브로커가 프로듀서로부터 레코드를 받아서 로컬디스크에 쓰고, 다른 브로커에도 성공적 복제시 
  - 첫번째 브로커가 프로듀서로 응답을 보내기 전에 크래시가 나면 프로듀서는 request.timeout.ms만큼 대기한뒤 재전송
  - 이대 새로 보낸 메시지는 이미 메시지를 받은 바 있는 새 리더 브로커로 전달 -> 메시지 중복 저장
- true 설정이 이러한 사태 방지 -> 동일 번호 레코드면 하나만 저장, DuplicateSequenceException
## 3.5 시리얼라이저
- 카프카는 StringSerializer, IntegerSerializer, ByteSerializer 포함
- 그러나 더 필요

### 3.5.1 커스텀 시리얼라이저
- 카프카로 전송객체가 문자열이나 정수값이 아닐 경우 
  - 레코드를 생성하기 위해 에이브로, 스리프트, 프로토버프와 같은 범용 직렬화 라이브러리 사용(강력히 권고)
  - 사용하고 있는 객체를 직렬화 위해 커스텀 직렬화 로직 작성
- 객체에 맞는 커스텀 시리얼라이저를 만들 경우 객체의 변환(id 값이 int에서 long 변환), 추가(startDate추가)시 새 형식 사이에 호환성을 유지해야 하는 심각한 문제 발생
- 그러므로 범용 라이브러리 사용

### 3.5.2 아파치 에이브로를 사용해서 직렬화
- 보통 json 형식으로 정의
- 메시지를 쓰는 애플리케이션이 새로운 스키마로 전환하더라도 기존 스키마와 호환성을 유지하는 한 변경이나 업데이트 없이 데이터 처리 가능
- 사라진 필드를 요청하거나 없는 필드를 요청하면 null반환하므로 사용에 유리(예외나 에러 발생 X)
- 주의점
  - 데이터를 쓸 대 사용하는 스키마와 읽을 때 기대하는 스키마가 호환되어야 한다.
  - 역직렬화를 할 때는 데이터를 쓸 때 사용했던 스키마 접근이 가능해야 한다.

### 3.5.3 카프카에서 에이브로 레코드 사용하기
- 에이브로 파일은 파일 안에 전체 스키마를 저장함으로써 약간의 오버헤드를 감수해야 함
- 카프카 레코드에 전체 스키마를 저장할 경우 전체 레코드 사이즈는 2배 이상이 도리 수 있다
- 하지만 에이브로 레코드를 읽을 때 스키마 전체를 필요로 하므로 어딘가 저장해야 한다.
- 그래서 스키마 레시스트리 아키텍쳐 패턴을 사용
- 핵심 아이디어는 카프카에 데이터를 쓰기 위해 사용되는 모든 스키마 레지스트리에 저장한다는 것
  - 그리고 카프카에 쓰는 레코드에서 사용된 스키마의 고유 식별자만 심어주는 되는 것

## 3.6 파티션
- ProduceRecord 객체는 토픽, 키, 밸류의 값을 포함
- 키값이 없어도 생성 가능하긴 하다.
  - 레코드는 현재 사용 가능한 토픽의 파티션 중 하나에 랜덤하게 저장.
  - 라운드 로빈 알고리즘 사용(접착성 처리 위해)
- 키값이 지정된 상황의 경우 키값을 해시한 결과를 기준으로 파티션 특정
  - 토픽의 모든 파티션 해당
- 기본 파티셔너가 사용될 대 특정한 키값에 대응되는 파티션은 파티션 수가 변하지 않는 한 변하지 않는다.

### 3.6.1 커스텀 파티셔너 구현하기
- 특정한 부분만 특정 파티션에 저장하고 다른 레코드들은 해시값을 사용해 파티션 할당한다면 커스텀 파티셔너를 구현해야 한다.

## 3.7 헤더
- 레코드 헤더는 카프카 레코드의 키/밸류 값을 건드리지 않고 추가 메타데이터를 ㅣㅅㅁ을 대 사용
- 주된 용도는 메시지의 전달 내역 기록
- 헤더는 순서가 있는 키/밸류 쌍의 집합
- 키는 스트링

## 3.8 인터셉터
- 코드를 고치지 않으면서 작동 변경해야 하는경우
- 모든 애플리케이션에 동일한 작동을 집어넣는다거나 원래 코드를 사용할 수 없는 경우 인터셉터 사용
- onSend
  - 프로듀서가 레코드를 브로커로 보내기 전, 직렬화되기 직전에 호출
  - 수정도 가능 유효한 레코드 리턴하도록만 주의
- onAcknolegement
  -카프카 브로커가 응답을 보낸 클라이언트가 받았을 때 호출 정보 읽기만 가능

## 3.9 쿼터, 스로틀링
- 카프카 브로커에는 쓰기/읽기 속도를 제한할 수 있는 기능이 있다. 
- 한도(쿼터) 설정
  - 쓰기
  - 읽기
  - 요청
- 쓰기와 읽기는 데이터를 전송하거나 받는 속도를 초당 바이트 수 단위로 제한
- 요청은 브로커가 요청을 처리하는 시간 비율 단위로 제한
