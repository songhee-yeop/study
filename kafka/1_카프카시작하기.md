# 카프가 시작하기

## 1.1 발행/구독 메시지 전달
전송자가 데이터를 보낼때 직접 수신자로 보내지 않는다.
대개 발행된 메시지를 전달받고 중계해주는 브로커가 있다.

###  1.1.1 초기의 발행 구독/시스템
- 어딘가로 모니터링 지표를 보내야 하는 앱 개발시 지표를 대시보드 형태로 보여주는 앱으로 연결을 생성하고 그 연결을 통해 지표를 전송하는 방법으로 개발
- 장기간 분석시 지표를 받아서 저장하고 분석하는 서비스를 새로 하나 만든다. 이 서비스를 작동하려면 앱을 고쳐서 두 시스템에 지푯값을 쓰게 만들고 세개가 되면 이 두서비스에 똑같은 연결을 또 만든다.
  - 결국 복잡해져서 연결 추적이 더 힘들어진다.
- 모든 앱으로부터 지표를 받는 하나의 앱을 만들고 이 지푯값을 필요로 하는 시스템에 질의할 수 있도록 해주는 서버 제공
  - 이게 바로 바랭/구독 시스템

### 1.1.2 개별 메시지 큐 시스템
- 지표와 마찬가지로 로그 메시지에 대해서도 비슷하게 작업
- 만약에 지푯값 발행/구독, 로그메시지 발행/구독, 사용자추적 발행/구독 3개의 발행/구독 시스템이 있을 경우 포인트투포인트 연결보다 바람직하지만 중복지 많다.
- 버그도 한계도 제각각인 다수의 큐 시스템을 유지 관리해야 한다.
  - 메시지 교환 필요로 하는 사례 추가 가능성
- 비지니스가 확장됨에 따라 함께 확장되는 중앙집중화된 시스템이 필요하다

## 1.2 카프가 입문
- 위 문제를 해결하기 위해 나온게 카프카
- 분산 커밋 로그 or 분산 스트리밍 플랫폼
- fs나 db 커밋 로그는 모든 트랜잭션 기록을 지속성 있게 보존함으로써 시스템의 상태를 일관성있게 복구할 수 있도록 고안
- 카프카에 저장된 데이터는 순서를 유지한채로 지속성있게 보관되며 읽을 수 있다.
- 확장시 성능 향상, 실패해도 데이터 사용에는 문제가 없도록 분산 저장

### 1.2.1 메시지와 배치
- 카프카에서 데이터의 기본 단위 = 메시지
- 카프카의 입장에서 메시지는 단순히 바이트의 배열일 뿐이기 때문에 데이터에는 형식이나 의미가 없다.
- 메시지는 키라 불리는 메타데이터를 포함할 수도 있다.(그러나 키도 특별한 의미 없는 바이트 배열)
- 가장 간단한 방법은 키값에서 일정한 해시값을 생성한 후 이 값을 토픽의 파티션 수로 나눴을 때 나오는 나머지 값에 해당하는 파티션에 메시지 저장
- 카프카는 효율성을 위해 메시지를 배치(토피의 파티션에 쓰여지는 메시지들의 집합) 단위로 저장
  - 오버헤드 줄이기 위해
  - 지연과 처리량 사이에 트레이드 오프 발생
- 약간의 처리 능력을 들여서 압축되는 경우가 많다.

### 1.2.2 스키마
- 메시지는 단순한 바이트 배열일 뿐이지만, 내용을 이해하기 쉽도록 구조(스키마) 부여 권장
- 가장 간단한 방법은 JSON, XML
  - 하지만 처리 기능이나 호환성 유지 떨어짐
  - Avro 선호
    - 조밀한 직렬화 형식 제공, 스키마 변경되더라도 코드 생성 x, 강력한 데이터 타이핑, 상하위 호환헝 제공
- 카프카에서는 일관적인 데이터 형식이 중요
  - 잘 저장된 스키마를 공유 저장소에 저장함으로써 카프카는 두 버전 형식 메시지 처리 가능
  - 스키마와 직렬화는 3장에서 다시

### 1.2.3 토픽과 파티션
- 카프카에 저장되는 메시지는 토픽 단윈로 분류
- 데이터베이스의 테이블이나 fs의 폴더
- 토픽은 여러개의 파티션으로 나뉨
- 파티션은 하나의 로그에 해당
- 파티션에 메시지가 쓰여질 때는 추가만 가능한 형태, 읽을 때는 맨 앞부터 제일 끝까지의 순서로 읽힘
- 대개 토픽에 여러개의 파티션이있는 만큼 토픽 안의 메시지 전체에 대해 순서 보장 x 단일 파티션 안에서만 보장
- 하나의 토픽이 여러개의 서버로 수평적으로 확장되어 하나의 서버의 용량을 넘어가는 성능을 보여줄 수 있다.
- 파티션은 복제될 수 있다.
  - 서도 다른 서버들이 동일한 파티션의 복제본을 저장하고 있기 때문에 하나에 장애가 발생한다고 해서 R/W 못하는 상황이 벌어지지 않는다.
- 스트림은 하나의 토픽에 저장된 데이터로 간주
  - 프로듀서로부터 컨슈머로의 데이터 흐름

### 1.2.4 프로듀서와 컨슈머
- 프로듀서
  - 새로운 메시지 생성
  - 어떤 경우에는 프로듀서가 특정한 파티션을 지정해서 메시지를 쓰기도 한다.
- 컨슈머
  - 메시지 읽음
  - 컨슈머는 1개 이상의 토픽 구독, 파티션에 쓰여진 순서대로 읽음
  - 컨슈머는 메시지의 offset을 기록함으로써 어느 메시지까지 읽었는지를 유지
  - offset은 카프카가 메시지를 저장할 때 각각의 메시지에 부여해주는 메타데이터
  - 파티션별로 다음번에 사용 가능한 오프셋 값을 저장함(카프카 자체에)
- 컨슈머 그룹
  - 토픽에 저장된 데이터를 읽어오기 위해 협업하는 하나 이성의 컨슈머
  - 각 파티션이 하나의 컨슈머에 의해서만 읽히도록 한다.
  - 하나의 컨슈머가 여러개의 파티션을 읽을수도 있다.
- 소유권
  - 컨슈머에서 파티션으로의 대응 관계

### 1.2.5 브로커와 클러스터
- 브로커
  - 하나의 카프카 서버
  - 프로듀서러부터 메시지 전달 받아 offset을 할당한 뒤 디스크 저장소에 씀
  - 컨슈머의 파티션 읽기 요청 역시 처리하고 발행된 메시지 보냄
- 클러스터
  - 카프카 브로커는 클러스터의 일부로서 작동하도록 설계
  - 하나의 클러스터 안에 여러개의 브로커 포함 가능
- 컨트롤러
  - 하나의 클러스터 안에 여러개의 브로커 중에 하나가 클러스터의 컨트롤러 역할
  - 현재 작동중인 브러커중 하나 자동 선정
  - 파티션을 브로커에 할당해주거나 장애가 발생한 브로커를 모니터랑하는 관리 기능
- 파티션 리더
  - 클러스터 안의 브로커 중 하나
-팔로워
  - 복제된 파티션이 여러 브로커에 할당
- 복제
  - 파티션의 메시지를 중복 저장해서 리더 브로커에 장애 발생이 이어 받음
- 모든 프료서는 리버 브로커에 메시지를 발행해야 하지만, 컨슈머는 리더나 팔로워 중 하나로부터 데이터를 일거올 수 있다. 
- 아파치 카프카의 핵심 기능 -> 일정기간 메시지를 지속성있게 보관하는 보존 기능
  - 기간이나, 크기 넘을 시 메시지는 만료되어 삭제 그 이외에는 보존
  - 토픽에는 로그 압착 기능 설정 가능 -> 키를 가진 메시지 중 가장 최신만 보존

### 1.2.6 다중 클러스터
- 다수의 클러스터를 운영하는것이 더 나은 경우
  - 데이터 유형별 분리
  - 보안 요구사항 충족시키기 위한 격리
  - 재해 복구 대비 다중 데이터 센터
- 카프카 프로젝트는 데이터를 다른 클러스터로 복제하는 데 사용되는 미러메이커라는 툴을 포함

## 1.3 왜 카프카인가

### 1.3.1 다중 프로듀서
- 카프카는 여러 프로듀서 처리 가능
- 많은 프론트엔드 시스템으로부터 데이터 수집하고 일관성 유지에 제격

### 1.3.2 다중 컨슈머
- 많은 컨슈머가 간섭 없이 어떠한 메시지 스틞 읽게 설계

### 1.3.3 디스크 기반 보존
- 메시지 지속성 있게 저장
- 느린 처리 속도나 트래픽 폭주로인한 데이터 유실 위험 x

### 1.3.4 확장성
- 유연한 확장성. 
- 하나의 브로커 => 수백개의 브로커로 구성된 대규모 개발용 클러스터로 옮기기만 하면 됨.
- 카프카 클러스터는 작동중에도 시스템 전체의 가용성에 영향을 주지 않으면서 확장 가능

### 1.3.5 고성능
- 발행된 메시지가 컨슈머에게 전달될 때까지 1초도 안걸리면서도 프로듀서 컨슈머 브로커 모두가 매우 큰 메시지 스트림을 쉽게 다를수 있도록 수평적으로 확장 될 수 있음

### 1.3.6 플랫폼 기능
- 유연성 갖춘 API와 라이브러리 잇음.
- ex) 카프카 스트림즈, 카프카 커넥터

## 1.4 데이터 생태계
- 아파치 카프카는 데이터 셍태계에 있어서 순환 시스템 제공
- 모든 클라이언트에 대해 일관된 인터페이스 제공하면서 다양한 infrastructure 요소들 사이에 메시지 전달

### 1.4.1 이용사례
- 활동 추적
- 메시지 교환
  - 사용자에게 알림을 보내야 하는 앱에서 활용 가능
- 지표 및 로그 수집
  - 모니터링과 경보를 맡고 있는 시스템이 이 지푯값들을 가져다 사용
  - 엘라스틱서치와 같은 로그 검색 전용 시스템이나 보안 분석 앱으로 보내질 수 있다.
- 커밋 로그
  - 앱은 스팀을 지켜봄으로써 실시간 업데이트 가능
  - 토픽에 키별로 마지막 값 하나만을 보존하는 로그 압착 기능을 사용해서 로그 오래 보존 가능
- 스트림 처리
  - 메시지가 생성되자마자 실시간으로 데이터 처리

### 1.5 카프카의 기원
- 링크드인 내부에서 데이터 파이프라인 문제를 해결하기 위해 개발

### 1.5.1 링크드인이 직면한 문제
- 데이터 저장하는 커스텀 수집기와 지표를 수집하는 시스템을 돌리고 있었는데 결함이 있었다.
- 지표가 수집되는 간격이 긴데다가 앱 담당자가 자신의 앱에서 수집된 지표를 관리할 수 없었음.
- 일관성 없었음
- 같은 시기에 사용자 활동 정보 추적 시스템도 문제가 많았음 xml이라 일관성이 없고 파싱 문제

### 1.5.2 카프카의 탄생
- 링크드인 개발팀이 개발
  - 푸시 풀 모델 사용해서 프로듀서와 컨슈머 분리
  - 다수의 컨슈머가 사용하도록 메시지 교환 시스템의 데이터를 영속적으로 저장
  - 높은 메시지 처리량
  - 시스템 수평 확장
- 아파치 Avro와 함께 사용

### 1.5.3 오픈소스
- 깃허브에 공개
- 아파치 카프카에 연관된 오픈소스 프로젝트도 많다.

### 1.5.4 상업적 제품
- GCP에서 카프카 매니지드 서비스 제공
- AWS에서 Microsoft Azure 에서도 제공

### 1.5.5 이름
- 프란츠 카프카 좋아해서 만들었음.